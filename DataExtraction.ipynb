{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hardik74658/Internship_Project_Herbalife_Neutrition_Sales_Analysis_2022-2024/blob/main/DataExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(pdf_document.page_count):\n",
        "        page = pdf_document.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "def parse_order_details(text):\n",
        "    order_number = re.search(r'Order Number\\s*(\\S+)', text).group(1).strip()\n",
        "    order_date = re.search(r'Order Date\\s*(\\d{2}-\\d{2}-\\d{4})', text).group(1).strip()\n",
        "    order_status = re.search(r'Order Status\\s*(.*)', text).group(1).strip()\n",
        "    invoice_number_match = re.search(r'Invoice Number:\\s*(\\S+)', text)\n",
        "    invoice_number = invoice_number_match.group(1).strip() if invoice_number_match else None\n",
        "\n",
        "    purchased_by_match  = re.search(r'Purchased By\\s*(.*)\\nID:', text)\n",
        "    purchased_by = purchased_by_match.group(1).strip()if purchased_by_match else None\n",
        "\n",
        "    ship_to_match = re.search(r'Ship To\\s*(.*?)(?=Shipping Method)', text, re.DOTALL)\n",
        "    ship_to = ship_to_match.group(1).strip() if ship_to_match else None\n",
        "    amount_paid_match = re.search(r'Amount Paid\\s*₹ ([\\d,]+.\\d{2})', text)\n",
        "    amount_paid =amount_paid_match.group(1).strip() if amount_paid_match else None\n",
        "\n",
        "    grand_total_match = re.search(r'Grand Total :\\s*₹ ([\\d,]+.\\d{2})', text)\n",
        "    grand_total = grand_total_match.group(1).strip if grand_total_match else None\n",
        "    # invoice_number=0\n",
        "\n",
        "    # Extract discount information\n",
        "    discount_match = re.search(r'Discount\\s*(\\d{2} %)', text)\n",
        "    discount = discount_match.group(1).strip() if discount_match else None\n",
        "\n",
        "    delivery_charges_match = re.search(r'Delivery Charges:\\s*₹\\s*([\\d,]+.\\d{2})', text)\n",
        "    delivery_charges = delivery_charges_match.group(1) if delivery_charges_match else None\n",
        "    # delivery_charges=0\n",
        "\n",
        "    # Extract item details\n",
        "    item_pattern = re.compile(r'(?:ITEM\\s+)?\\s+(\\d+)\\s+((?:[A-Z][A-Z0-9 -]+\\s*)+)SKU\\s*(\\w+)\\s*\\(Product\\)',re.DOTALL)\n",
        "    items = item_pattern.findall(text)\n",
        "\n",
        "    # Clean up item names (remove extra spaces)\n",
        "    items = [(qty, ' '.join(name.split()), sku) for qty, name, sku in items]\n",
        "\n",
        "    return order_number,delivery_charges, order_date, order_status, invoice_number, purchased_by, ship_to, amount_paid, grand_total, discount, items\n",
        "\n",
        "def create_dataframe(order_number,delivery_charges, order_date, order_status, invoice_number, purchased_by, ship_to, amount_paid, grand_total, discount, items):\n",
        "    data = []\n",
        "    for item in items:\n",
        "        quantity_shipped, item_name, sku = item\n",
        "        data.append([\n",
        "            order_number,delivery_charges, order_date, order_status, invoice_number, purchased_by, ship_to,\n",
        "            amount_paid, grand_total, discount, quantity_shipped, item_name, sku\n",
        "        ])\n",
        "\n",
        "    columns = [\n",
        "        'Order Number','Delivery Charges', 'Order Date', 'Order Status', 'Invoice Number', 'Purchased By', 'Ship To',\n",
        "        'Amount Paid', 'Grand Total', 'Discount', 'Quantity Shipped', 'Item', 'SKU'\n",
        "    ]\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    return df\n",
        "\n",
        "# Directory containing all PDFs\n",
        "pdf_directory = 'drive/MyDrive/2022/12_Dec'\n",
        "\n",
        "# Initialize an empty list to collect all DataFrames\n",
        "all_dfs = []\n",
        "\n",
        "# Iterate through each PDF file in the directory\n",
        "for filename in os.listdir(pdf_directory):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(pdf_directory, filename)\n",
        "\n",
        "        # Extract text from PDF\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "        # Parse order details\n",
        "        order_number,delivery_charges, order_date, order_status, invoice_number, purchased_by, ship_to, amount_paid, grand_total, discount, items = parse_order_details(text)\n",
        "\n",
        "\n",
        "\n",
        "        # Create DataFrame\n",
        "        df = create_dataframe(order_number,delivery_charges, order_date, order_status, invoice_number, purchased_by, ship_to, amount_paid, grand_total, discount, items)\n",
        "\n",
        "        # Append DataFrame to the list\n",
        "        all_dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "if all_dfs:\n",
        "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "    # Save to CSV\n",
        "    output_csv_path = 'Dec2022.csv'\n",
        "    combined_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Data saved to {output_csv_path}\")\n",
        "else:\n",
        "    print(\"No PDF files found or no data extracted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W-MGHFosSwW",
        "outputId": "eff00097-951d-42a4-976b-1ccde0e2fa8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.7)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.6 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.24.6)\n",
            "Data saved to Dec2022.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CG7WjKWUfpQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35597d8-73e1-40f3-ff1d-77fc3ed3a179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KswDPY0e8-yz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}